{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1. python train.py\n",
    "2. python test.py\n",
    "\n",
    "test 폴더에 바꾸고 싶은 노래 넣기\n",
    "config.py의 direction = \"B2A\"는 B를 A로 바꿈.\n",
    "\n",
    "결과는 sample폴더 밑에 생김"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyworld\n",
      "  Using cached https://files.pythonhosted.org/packages/dc/8d/f83aef293df2fb9f3435f129ea7a02f55fd0fe04ada69bf4207d5ffbc92c/pyworld-0.2.8.tar.gz\n",
      "Requirement already satisfied: numpy in c:\\users\\kim yuum\\appdata\\local\\conda\\conda\\envs\\yum_env\\lib\\site-packages (from pyworld) (1.17.4)\n",
      "Requirement already satisfied: cython>=0.24.0 in c:\\users\\kim yuum\\appdata\\local\\conda\\conda\\envs\\yum_env\\lib\\site-packages (from pyworld) (0.29.14)\n",
      "Building wheels for collected packages: pyworld\n",
      "  Building wheel for pyworld (setup.py): started\n",
      "  Building wheel for pyworld (setup.py): finished with status 'done'\n",
      "  Created wheel for pyworld: filename=pyworld-0.2.8-cp35-cp35m-win_amd64.whl size=221958 sha256=80ed458a1f29a64c9145e8063227d99b078ce0e946293c3bd2f06f0cc9df4884\n",
      "  Stored in directory: C:\\Users\\Kim Yuum\\AppData\\Local\\pip\\Cache\\wheels\\c3\\58\\e5\\a7e39ab92c56825f976970b97066753c68406c7fb0d80d4a4a\n",
      "Successfully built pyworld\n",
      "Installing collected packages: pyworld\n",
      "Successfully installed pyworld-0.2.8\n"
     ]
    }
   ],
   "source": [
    "!pip install pyworld"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Constructing MCEPs....\n"
     ]
    }
   ],
   "source": [
    "%run train.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W1225 23:47:12.588104  2964 module_wrapper.py:139] From C:\\Users\\Kim Yuum\\Desktop\\TOBIGS2\\Project\\sst\\cycle_began.py:37: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W1225 23:47:12.634953  2964 module_wrapper.py:139] From C:\\Users\\Kim Yuum\\Desktop\\TOBIGS2\\Project\\sst\\Utils\\networks.py:104: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n",
      "W1225 23:47:12.634953  2964 deprecation.py:323] From C:\\Users\\Kim Yuum\\Desktop\\TOBIGS2\\Project\\sst\\Utils\\layers.py:233: conv1d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.keras.layers.Conv1D` instead.\n",
      "W1225 23:47:12.657838  2964 deprecation.py:323] From C:\\Users\\Kim Yuum\\AppData\\Local\\conda\\conda\\envs\\yum_env\\lib\\site-packages\\tensorflow_core\\python\\layers\\convolutional.py:218: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.__call__` method instead.\n",
      "W1225 23:47:13.011709  2964 lazy_loader.py:50] \n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "W1225 23:47:50.980073  2964 module_wrapper.py:139] From C:\\Users\\Kim Yuum\\Desktop\\TOBIGS2\\Project\\sst\\cycle_began.py:112: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.\n",
      "\n",
      "W1225 23:47:55.157386  2964 module_wrapper.py:139] From C:\\Users\\Kim Yuum\\Desktop\\TOBIGS2\\Project\\sst\\cycle_began.py:133: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
      "\n",
      "W1225 23:50:32.720593  2964 module_wrapper.py:139] From C:\\Users\\Kim Yuum\\Desktop\\TOBIGS2\\Project\\sst\\cycle_began.py:22: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
      "\n",
      "W1225 23:50:37.584610  2964 module_wrapper.py:139] From C:\\Users\\Kim Yuum\\Desktop\\TOBIGS2\\Project\\sst\\cycle_began.py:23: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "W1225 23:50:37.782437  2964 module_wrapper.py:139] From C:\\Users\\Kim Yuum\\Desktop\\TOBIGS2\\Project\\sst\\cycle_began.py:24: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.\n",
      "\n",
      "W1225 23:51:25.460197  2964 module_wrapper.py:139] From C:\\Users\\Kim Yuum\\Desktop\\TOBIGS2\\Project\\sst\\cycle_began.py:31: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n",
      "\n",
      "W1225 23:51:25.460197  2964 module_wrapper.py:139] From C:\\Users\\Kim Yuum\\Desktop\\TOBIGS2\\Project\\sst\\cycle_began.py:31: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W1225 23:52:05.316735  2964 module_wrapper.py:139] From C:\\Users\\Kim Yuum\\Desktop\\TOBIGS2\\Project\\sst\\cycle_began.py:218: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.\n",
      "\n",
      "W1225 23:52:05.364640  2964 module_wrapper.py:139] From C:\\Users\\Kim Yuum\\Desktop\\TOBIGS2\\Project\\sst\\cycle_began.py:223: The name tf.summary.merge is deprecated. Please use tf.compat.v1.summary.merge instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start CycleBeGan Training...\n",
      "Epoch : 0 \n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os, time\n",
    "\n",
    "from cyclegan import CycleGAN\n",
    "from cycle_began import CycleBeGAN\n",
    "from preprocess import *\n",
    "import pickle\n",
    "\n",
    "n_epochs = 1\n",
    "mini_batch_size = 1  # mini_batch_size = 1 is better\n",
    "generator_learning_rate = 0.0002\n",
    "generator_learning_rate_decay = generator_learning_rate / 200000\n",
    "discriminator_learning_rate = 0.0001\n",
    "discriminator_learning_rate_decay = discriminator_learning_rate / 200000\n",
    "sampling_rate = 16000\n",
    "num_mcep = 24\n",
    "frame_period = 5\n",
    "## n_frames 128 is about 0.5 sec\n",
    "n_frames = 512\n",
    "lambda_cycle = 10\n",
    "lambda_identity = 5\n",
    "# 추가\n",
    "gamma_A = 0.5\n",
    "gamma_B = 0.5\n",
    "lambda_k_A = 0.001\n",
    "lambda_k_B = 0.001\n",
    "balance_A = 0\n",
    "balance_B = 0\n",
    "# kta 초기값\n",
    "k_t_A = 0\n",
    "k_t_B = 0\n",
    "\n",
    "with open('A.txt', 'rb') as f:\n",
    "    A_norm = pickle.load(f)\n",
    "\n",
    "with open('B.txt', 'rb') as k:\n",
    "    B_norm = pickle.load(k)\n",
    "\n",
    "model = CycleBeGAN(num_features = n_features, log_dir = log_dir)\n",
    "\n",
    "print(\"Start CycleBeGan Training...\")\n",
    "for epoch in range(n_epochs) :\n",
    "    print(\"Epoch : %d \" % epoch ) \n",
    "    start_time = time.time()\n",
    "    train_A, train_B = sample_train_data(dataset_A=A_norm, dataset_B=B_norm,n_frames=n_frames) # random data\n",
    "\n",
    "    n_samples = train_A.shape[0]\n",
    "\n",
    "    for i in range(n_samples) : # mini_ batch_size = 1\n",
    "        n_iter = n_samples * epoch + i\n",
    "        if n_iter % 50 == 0:\n",
    "            k_t_A = k_t_A + (lambda_k_A *balance_A)\n",
    "            if k_t_A > 1:\n",
    "                k_t_A = 1\n",
    "            if k_t_A <= 0 :\n",
    "                k_t_A = 0\n",
    "            \n",
    "            k_t_B = k_t_B + (lambda_k_B *balance_B)\n",
    "            if k_t_B > 1:\n",
    "                k_t_B = 1\n",
    "            if k_t_B <= 0:\n",
    "                k_t_B = 0\n",
    "    \n",
    "        if n_iter > 10000 :\n",
    "            identity_lambda = 0\n",
    "        if n_iter > 200000 :\n",
    "            generator_lr = max(0, generator_lr - generator_lr_decay)\n",
    "            discriminator_lr = max(0, discriminator_lr - discriminator_lr_decay)\n",
    "\n",
    "        start = i\n",
    "        end = start + 1\n",
    "        generator_loss, discriminator_loss, measure_A, measure_B, k_t_A, k_t_B, balance_A, balance_B = model.train(\n",
    "#                         input_A=dataset_A[start:end], input_B=dataset_B[start:end], \n",
    "                        input_A=train_A[start:end], input_B=train_B[start:end],\n",
    "                        lambda_cycle=lambda_cycle,\n",
    "                        lambda_identity=lambda_identity,\n",
    "                        gamma_A=gamma_A, gamma_B=gamma_B, lambda_k_A=lambda_k_A, lambda_k_B=lambda_k_B,\n",
    "                        generator_learning_rate=generator_learning_rate,\n",
    "                        discriminator_learning_rate=discriminator_learning_rate, \n",
    "                        k_t_A = k_t_A, k_t_B = k_t_B)\n",
    "    end_time = time.time()\n",
    "    epoch_time = end_time-start_time\n",
    "    print(\"Generator Loss : %f, Discriminator Loss : %f, Time : %02d:%02d\" % (generator_loss, discriminator_loss,(epoch_time % 3600 // 60),(epoch_time % 60 // 1)))\n",
    "    model.save(directory = model_dir, filename = \"Cycle_BeGan\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Constructing MCEPs....\n"
     ]
    }
   ],
   "source": [
    "%run train.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
